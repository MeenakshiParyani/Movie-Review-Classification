{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1359,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy import spatial\n",
    "\n",
    "import matplotlib.pyplot as plt # side-stepping mpl backend\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "# from sklearn import cross_validation\n",
    "import heapq\n",
    "import string\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "trainingData  = pd.read_csv('data/train.dat.txt', sep=\"\\t\", encoding='utf-8', header=None, names=[\"rating\",\"review\"])[:2];\n",
    "testData = pd.read_csv('data/test.dat.txt', sep=\"\\t\", encoding='utf-8', header=None, names=[\"review\"])[:2];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Cleaning\n",
      "   rating                                             review\n",
      "0      -1  Although a film with Bruce Willis is always wo...\n",
      "After Cleaning\n",
      "[[u'although', u'film', u'bruce', u'willis', u'always', u'worth', u'watching', u'better', u'skip', u'watched', u'television', u'plunk', u'cash', u'lucky', u'plot', u'develops', u'slowly', u'slowly', u'although', u'first', u'minutes', u'quite', u'believable', u'gets', u'unbelievable', u'towards', u'highly', u'questionable', u'seasoned', u'soldier', u'like', u'waters', u'would', u'disobey', u'direct', u'orders', u'even', u'would', u'rest', u'platoon', u'would', u'know', u'puts', u'direct', u'danger', u'know', u'certainly', u'follow', u'heck', u'says', u'despite', u'direct', u'orders', u'remember', u'still', u'nice', u'scenes', u'movie', u'somewhat', u'save', u'village', u'total', u'population', u'massacred', u'rebels', u'well', u'save', u'dozen', u'villagers', u'rest', u'already', u'killed', u'strange', u'part', u'take', u'trucks', u'rebels', u'left', u'behind', u'rather', u'foot', u'maybe', u'roads', u'unsafe', u'explanation', u'anyway', u'think', u'earned', u'movie', u'point', u'gave', u'made', u'movie', u'insult', u'brain', u'hence', u'completely', u'unbelievable', u'group', u'soldiers', u'kill', u'many', u'rebels', u'without', u'hurt', u'killed', u'near', u'loose', u'comrades', u'fight', u'army', u'nearly', u'believe', u'fight', u'army', u'many', u'kill', u'hundreds', u'loose', u'rounds', u'round', u'ammo', u'never', u'grenades', u'claymore', u'mines', u'machine', u'even', u'stuff', u'carrying', u'around', u'even', u'laptop', u'shows', u'activity', u'enemy', u'rebels', u'laptop', u'battery', u'goes', u'days', u'really', u'think', u'crap.', u'guess', u'turn', u'brain', u'completely', u'accept', u'rebels', u'bunch', u'idiots', u'give', u'movie', u'high', u'rating', u'skip', u'saves', u'time'], [u'movie', u'slower', u'molasses', u'january', u'alaska', u'togeather', u'preview', u'award', u'managing', u'every', u'seconds', u'interisting', u'preview', u'wake', u'people', u'watching', u'several', u'times', u'felt', u'woken', u'film', u'taken', u'hoping', u'something', u'actually', u'happen', u'nothing', u'ever', u'easy', u'loose', u'track', u'people', u'motives', u'characters', u'flat', u'uninteristing', u'movie', u'hoped', u'everyone', u'would', u'died', u'everyone', u'runs', u'around', u'either', u'contemptible', u'petty', u'pitiful', u'usually', u'three', u'worse', u'watched', u'minute', u'added', u'features', u'kicks', u'giggles', u'understand', u'people', u'smug', u'socially', u'aware', u'spend', u'time', u'movie', u'patting', u'back', u'might', u'worth', u'watching', u'brought', u'expecting', u'excitement', u'lecture', u'social', u'awareness', u'blery', u'eyes', u'sandman']]\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "print('Before Cleaning');\n",
    "print (trainingData[0:1])\n",
    "\n",
    "def preProcess(reviews):\n",
    "#     print(reviews);\n",
    "    processedReviews = [];\n",
    "    for review in reviews:\n",
    "        tokens = word_tokenize(review);\n",
    "        filteredTokens = [];\n",
    "        for token in list(tokens):\n",
    "#             print(token);\n",
    "            # if it is a stopword then eliminate\n",
    "            if token.lower() in stopwords.words('english'):\n",
    "#                 print('removing stopword ' + token);\n",
    "                continue;\n",
    "            # if it is punctuation then eliminate\n",
    "            if token.lower() in set(string.punctuation):\n",
    "#                 print('removing punct ' + token);\n",
    "                continue;\n",
    "            if len(token)<=3:\n",
    "#                 print('removing small ' + token);\n",
    "                continue;\n",
    "            token = token.lower();\n",
    "            filteredTokens.append(token);\n",
    "#         print(filteredTokens);\n",
    "        processedReviews.append(filteredTokens);\n",
    "#     print(len(processedReviews));\n",
    "    return processedReviews;\n",
    "print('After Cleaning')\n",
    "XTrain = preProcess(trainingData['review']);\n",
    "print(XTrain);\n",
    "print (len(XTrain));\n",
    "XTest = preProcess(testData['review']);\n",
    "print (len(XTest));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 191.\n",
      "Number of unique words: 152.\n",
      "191\n",
      "152\n"
     ]
    }
   ],
   "source": [
    "# count frequencies for all words in the Training data\n",
    "def countFrequency(data):\n",
    "    wordCountInData = Counter()\n",
    "    for d in data:\n",
    "    #     print(d);\n",
    "        for w in d:\n",
    "    #         print(w);\n",
    "            if w not in wordCountInData:\n",
    "                wordCountInData[w]=1\n",
    "            else:\n",
    "                wordCountInData[w] += 1\n",
    "    print(\"Number of unique words: %d.\" % len(wordCountInData));\n",
    "    return wordCountInData;\n",
    "\n",
    "wordCountInTrainingData = countFrequency(XTrain);\n",
    "wordCountInTestData = countFrequency(XTest);\n",
    "print(len(wordCountInTrainingData));\n",
    "print(len(wordCountInTestData));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191\n",
      "152\n"
     ]
    }
   ],
   "source": [
    "#Top percent of training data\n",
    "topPct = 1;\n",
    "topPctOfTraining = wordCountInTrainingData.most_common(int(round(len(wordCountInTrainingData)*topPct)));\n",
    "topPctOfTest = wordCountInTestData.most_common(int(round(len(wordCountInTestData)*topPct)));\n",
    "\n",
    "# Get a set of topPctOfTraining\n",
    "topPctOfTrainingSet = set()\n",
    "for word in topPctOfTraining:\n",
    "    topPctOfTrainingSet.add(word[0]);\n",
    "\n",
    "# Get a set of topPctOfTest\n",
    "topPctOfTestSet = set()\n",
    "for word in topPctOfTest:\n",
    "    topPctOfTestSet.add(word[0]);\n",
    "    \n",
    "# print(topPctOfTrainingSet);\n",
    "# print(topPctOfTestSet);\n",
    "print(len(topPctOfTrainingSet));\n",
    "print(len(topPctOfTestSet));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words common in both test and train: 17.\n"
     ]
    }
   ],
   "source": [
    "testTrainSet =  set.intersection(topPctOfTrainingSet,topPctOfTestSet);\n",
    "print(\"Number of unique words common in both test and train: %d.\" % len(testTrainSet));\n",
    "# print(testTrainSet);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "cnt = Counter(testTrainSet);\n",
    "top_percentile = 1.0\n",
    "features = cnt.most_common(int(round(len(cnt)*top_percentile)))\n",
    "featuresCount = len(features)\n",
    "# print(features);\n",
    "print(featuresCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "[u'even', u'made', u'point', u'movie', u'loose', u'scenes', u'first', u'times', u'every', u'take', u'characters', u'time', u'nothing', u'still', u'think', u'film', u'nice']\n"
     ]
    }
   ],
   "source": [
    "featureList= [];\n",
    "for feature in features:\n",
    "    featureList.append(feature[0])\n",
    "print(len(featureList));\n",
    "print(featureList);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Buid CSR matrix\n",
    "\n",
    "from collections import Counter\n",
    "from scipy.sparse import csr_matrix\n",
    "def build_matrix(docs):\n",
    "    r\"\"\" Build sparse matrix from a list of documents, \n",
    "    each of which is a list of word/terms in the document.  \n",
    "    \"\"\"\n",
    "    dim = len(featureList)\n",
    "    feature_set = set(featureList[:dim])\n",
    "    nrows = len(docs)\n",
    "    idx = {}\n",
    "    tid = 0\n",
    "    nnz = 0\n",
    "    for d in docs:\n",
    "#         print('d---')\n",
    "#         print(d)\n",
    "#         set_d = set(d)\n",
    "        set_d = set()\n",
    "        for word in d:\n",
    "#             print(word)\n",
    "            set_d.add(word);\n",
    "        print('set d--')\n",
    "        print(set_d);\n",
    "        print('features--')\n",
    "        print(feature_set);\n",
    "        d = list(set.intersection(feature_set,set_d))\n",
    "        print('common elemets %d',len(d));\n",
    "        print('com')\n",
    "        nnz += len(set(d))\n",
    "        for w in d:\n",
    "            print('adding word ', w) ;\n",
    "            if w not in idx:\n",
    "                idx[w] = tid\n",
    "                tid += 1\n",
    "    ncols = len(idx)\n",
    "    print(idx);\n",
    "    # set up memory\n",
    "    ind = np.zeros(nnz, dtype=np.int)\n",
    "    val = np.zeros(nnz, dtype=np.double)\n",
    "    ptr = np.zeros(nrows+1, dtype=np.int)\n",
    "    i = 0  # document ID / row counter\n",
    "    n = 0  # non-zero counter\n",
    "    # transfer values\n",
    "    for d in docs:\n",
    "        set_d = set(d)\n",
    "        d = list(set.intersection(feature_set,set_d))\n",
    "        cnt = Counter(d)\n",
    "        keys = list(k for k,_ in cnt.most_common())\n",
    "        l = len(keys)\n",
    "        for j,k in enumerate(keys):\n",
    "            ind[j+n] = idx[k]\n",
    "            val[j+n] = cnt[k]\n",
    "        ptr[i+1] = ptr[i] + l\n",
    "        n += l\n",
    "        i += 1\n",
    "            \n",
    "    mat = csr_matrix((val, ind, ptr), shape=(nrows, ncols), dtype=np.double)\n",
    "    mat.sort_indices()\n",
    "    \n",
    "    return mat\n",
    "\n",
    "\n",
    "def csr_info(mat, name=\"\", non_empy=False):\n",
    "    r\"\"\" Print out info about this CSR matrix. If non_empy, \n",
    "    report number of non-empty rows and cols as well\n",
    "    \"\"\"\n",
    "    if non_empy:\n",
    "        print(\"%s [nrows %d (%d non-empty), ncols %d (%d non-empty), nnz %d]\" % (\n",
    "                name, mat.shape[0], \n",
    "                sum(1 if mat.indptr[i+1] > mat.indptr[i] else 0 \n",
    "                for i in range(mat.shape[0])), \n",
    "                mat.shape[1], len(np.unique(mat.indices)), \n",
    "                len(mat.data)))\n",
    "    else:\n",
    "        print( \"%s [nrows %d, ncols %d, nnz %d]\" % (name, \n",
    "                mat.shape[0], mat.shape[1], len(mat.data)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ u\"Although a film with Bruce Willis is always worth watching, you better skip this one. I watched this one on television, so I didn't have to plunk down cash for it. Lucky me.<br /><br />The plot develops slowly, very slowly. Although the first 30 minutes or so are quite believable, it gets more and more unbelievable towards the end. It is highly questionable, if a seasoned soldier like Lt. Waters would disobey direct orders. And even if he would, if the rest of his platoon would. They know he puts them in direct danger, and they know they will certainly die if they follow him, but what the heck, he is our Lt. so let's do what he says (despite the direct orders, remember).<br /><br />Still, there are some nice scenes in this movie. They somewhat save a village, where the total population is being massacred by the rebels. Well, they save a dozen villagers or so, the rest was already killed. The strange part of it, that they did take the trucks which the rebels left behind. They rather go on foot. Maybe because the roads are unsafe, but there was no explanation for it. Anyway. I think this was what earned the movie the one point I gave it.<br /><br />What made this movie an insult to the brain and hence completely unbelievable is that a group of 7 soldiers can kill of so many rebels without being hurt or killed themselves. Only near the end they loose a few comrades. And that is only because they have to fight of an army of nearly 500 or more. Can you believe that?<br /><br />They fight of an army of so many, kill hundreds of them, and only loose a few of themselves. And they have rounds and round of ammo. Never run out of it. Grenades and claymore mines, an M60 machine gun and even an RPG. Where do they get this stuff. Carrying it around or what? They even got a laptop which shows them the activity of enemy rebels. And this laptop has a battery which goes on for days. Really? Who think up this crap.<br /><br />I guess if you turn off your brain completely and accept that the rebels are a bunch of idiots, you give this movie a high rating. If not, skip this one. It saves you time.\"\n",
      " u\"This movie was slower then Molasses in January... in Alaska. The man who put togeather the preview should get an award for managing to put every one of the 30 seconds that were interisting into the preview. I had to wake up the people I was watching it with, several times. After it was over, I felt bad for having woken them up. <br /><br />Most of the film is taken up with hoping something will actually happen, but nothing ever does. It was easy to loose track of people's motives, and the characters were flat and uninteristing. By the end of the movie, you just hoped everyone would died. Everyone runs around either being contemptible, petty, or pitiful, and usually all three. <br /><br />And worse, we watched a minute or two of the added features, just for kicks and giggles you understand, and all that we saw was people being smug about how socially aware they are. If they had spend the time on the movie that they did patting themselves on the back, it might have been worth watching. <br /><br />I was brought in expecting the excitement of '24.' I got a lecture on social awareness through the blery eyes of the sandman.\"\n",
      " u'I am so glad when i watch in every time the movie of (Ray) for the Sidney pottier of the 21st century (Jamie Foxx) who played this role as an evidence of his brilliant ability as an actor to take his position beside great actors in Hollywood by his golden supporting for the strong abilities of afro American actors all over the times and periods by his eternal work as an evidence for the eternity of Ray Charles as a grand prove for their legend appearance in every time by their success for winning Oscar prize as (best actor for leading role) an (best mixing sound) between fact and cinematic scenes upon Ray and Jamie as a mixing between two copies of Ray (ray of the past) and (ray of 2004 acted in the person of Jamie Foxx).It was nice from the director to choose those songs to be adapted with dramatical scenes in the accidents of film to enter for the atmosphere of success in legend corn with legend movies in Hollywood since 1893 till now and his cleverness of choosing Sharon Warrne in the role of Ray ,s mother that she succeeded in this role by brilliant analysis for the core of her character that Ray,s mother was the turning point for him upon her grew up to be independent on himself to take his place in this world and to be icon in his talent as (Nat king Cole , Louis Armstrong , Duke Ellington) and at the end of this film by receiving his honorable report from Gerogia and their decision to take his song (Georgia on my mind) the national anthem for this state he made his promise for his mother to be alive until now by his legend songs and brilliant life.'\n",
      " u'when I first heard about this movie, I noticed it was one of the most controversial films of the 1970s. I noticed the music was by Elton John, so I figured I had nothing to loose, so I got it. What a Surprise!!! The movie was awesome. It was true love is all about. The characters (Paul and Michelle) had no luxuries, no money, and sometimes no food, yet they were still happy. I recommended this film to all my friends, but they all critized my tastes, and even called me names, becuase the movie featured two minors naked. I think that only made the movie more realistic. The cinematography was great and it only come to show the great abilities of director Lewis Gilbert']\n",
      "set d--\n",
      "set([u'rating', u'What', u'Who', u'rebels', u'being', u'skip', u'laptop', u'saves', u'Lucky', u'rest', u'gun', u'brain', u'kill', u'go', u'follow', u'bunch', u'certainly', u'group', u'earned', u'(', u'point', u'claymore', u',', u'killed', u'better', u'to', u'only', u'Carrying', u'Although', u'save', u'villagers', u'worth', u'gave', u'it.', u'do', u'them', u'his', u'which', u'watching', u'very', u'know', u'they', u'despite', u'foot', u'highly', u'Where', u'him', u'nearly', u'enemy', u'like', u'trucks', u'did', u'die', u'Anyway', u'platoon', u'always', u'where', u'round', u'population', u'because', u'says', u'me.', u'some', u'direct', u'around', u'scenes', u'insult', u'Only', u'are', u'soldiers', u'our', u'Lt.', u'out', u'even', u\"n't\", u'what', u'give', u'for', u'plunk', u'Bruce', u'movie', u'mines', u'/', u'your', u'behind', u'stuff', u'run', u'7', u'got', u'get', u'?', u'shows', u'fight', u'dozen', u'loose', u'quite', u'completely', u'not', u'let', u'br', u'hundreds', u'by', u'on', u'puts', u'of', u'30', u'has', u'days', u'soldier', u'heck', u'Grenades', u'hence', u'Still', u'or', u'ammo', u'first', u'already', u'danger', u'battery', u'Willis', u'If', u'one', u'down', u'village', u'roads', u'total', u'rounds', u'plot', u'guess', u'would', u'army', u'Waters', u'there', u'idiots', u'.', u'few', u'slowly', u'goes', u'seasoned', u'themselves', u'was', u'500', u'>', u'questionable', u'that', u'explanation', u'crap.', u'Well', u'but', u'hurt', u'part', u'somewhat', u'turn', u'off', u'believe', u'with', u'he', u'And', u'television', u'made', u'this', u'cash', u'<', u'will', u'near', u'can', u'many', u'more', u'minutes', u'and', u'up', u'is', u'in', u'unsafe', u'it', u'accept', u'an', u'high', u'Lt', u'comrades', u'have', u'watched', u'believable', u'activity', u'orders', u'film', u'if', u'end', u'no', u')', u'Never', u'machine', u'strange', u'take', u'They', u'you', u'gets', u'nice', u'M60', u'unbelievable', u'towards', u\"'s\", u'I', u'Maybe', u'time', u'Can', u'develops', u'The', u'the', u'a', u'massacred', u'remember', u'It', u'think', u'rather', u'without', u'so', u'RPG', u'disobey', u'Really', u'left'])\n",
      "features--\n",
      "set([u'even', u'made', u'nice', u'point', u'movie', u'loose', u'scenes', u'times', u'every', u'take', u'characters', u'time', u'nothing', u'still', u'think', u'film', u'first'])\n",
      "('common elemets %d', 12)\n",
      "com\n",
      "('adding word ', u'even')\n",
      "('adding word ', u'made')\n",
      "('adding word ', u'point')\n",
      "('adding word ', u'movie')\n",
      "('adding word ', u'loose')\n",
      "('adding word ', u'scenes')\n",
      "('adding word ', u'take')\n",
      "('adding word ', u'time')\n",
      "('adding word ', u'first')\n",
      "('adding word ', u'think')\n",
      "('adding word ', u'film')\n",
      "('adding word ', u'nice')\n",
      "set d--\n",
      "set([u'giggles', u'all', u'just', u'being', u'over', u'through', u'had', u',', u'actually', u'to', u'does', u'blery', u'easy', u'pitiful', u'might', u'By', u'awareness', u'...', u'them', u'woken', u'watching', u'socially', u'Alaska', u'every', u'they', u'lecture', u'smug', u'minute', u'runs', u'contemptible', u'did', u'togeather', u'bad', u'uninteristing', u'either', u'two', u'everyone', u'slower', u'people', u'back', u'are', u'happen', u'excitement', u'for', u'managing', u'movie', u'/', u'seconds', u'Molasses', u'got', u'get', u'ever', u'we', u'who', u'This', u'loose', u'worse', u'br', u'put', u'on', u'about', u'of', u'worth', u'30', u'times', u'expecting', u'social', u'usually', u'or', u'features', u'into', u'one', u'brought', u'should', u'petty', u'would', u'three', u'been', u'.', u'Most', u'motives', u'taken', u'themselves', u'preview', u'was', u'>', u'flat', u'eyes', u'that', u'January', u'award', u'hoped', u'wake', u'kicks', u'with', u'And', u'up', u'<', u'will', u'were', u'and', u'hoping', u'then', u'is', u'it', u'an', u'patting', u'something', u'have', u'in', u'watched', u'saw', u'film', u'around', u'end', u'After', u'interisting', u'how', u\"'24\", u'you', u'several', u'added', u\"'s\", u'track', u'felt', u'sandman', u'but', u'characters', u'nothing', u'The', u'aware', u'died', u'man', u'a', u'Everyone', u'I', u\"'\", u'It', u'spend', u'time', u'understand', u'the', u'having', u'If'])\n",
      "features--\n",
      "set([u'even', u'made', u'nice', u'point', u'movie', u'loose', u'scenes', u'times', u'every', u'take', u'characters', u'time', u'nothing', u'still', u'think', u'film', u'first'])\n",
      "('common elemets %d', 8)\n",
      "com\n",
      "('adding word ', u'movie')\n",
      "('adding word ', u'loose')\n",
      "('adding word ', u'times')\n",
      "('adding word ', u'every')\n",
      "('adding word ', u'characters')\n",
      "('adding word ', u'time')\n",
      "('adding word ', u'nothing')\n",
      "('adding word ', u'film')\n",
      "set d--\n",
      "set([u'all', u'abilities', u'enter', u'over', u'atmosphere', u'report', u'afro', u'Ellington', u'Warrne', u'21st', u'mother', u'Oscar', u'character', u',', u'pottier', u'winning', u'to', u'choose', u'actors', u'his', u'Duke', u'Louis', u'watch', u'made', u'every', u'mixing', u'world', u'now', u'him', u'prize', u'success', u'she', u'dramatical', u'Ray', u'be', u'national', u'alive', u'up', u'past', u'choosing', u'anthem', u'Gerogia', u'best', u'for', u'movie', u'decision', u'since', u'state', u'between', u'honorable', u'receiving', u'supporting', u'turning', u'ability', u'corn', u'eternal', u'strong', u'legend', u'on', u'great', u'talent', u'brilliant', u'of', u'times', u's', u'place', u'(', u'adapted', u'.It', u'golden', u'Jamie', u'Sidney', u'point', u'acted', u'two', u'Foxx', u'promise', u'Hollywood', u'.', u'Armstrong', u'from', u'her', u'prove', u'leading', u'century', u'copies', u'by', u'their', u'was', u'until', u'life', u'himself', u'that', u'mind', u'American', u'evidence', u'with', u'glad', u'he', u'sound', u'king', u'grew', u'this', u'work', u'appearance', u'scenes', u'movies', u'those', u'Cole', u'my', u'at', u'and', u'Sharon', u'played', u'am', u'an', u'as', u'Georgia', u'periods', u'Nat', u'in', u'cleverness', u'film', u'ray', u'end', u')', u'song', u'when', u'actor', u'beside', u'till', u'role', u'take', u'grand', u'1893', u'nice', u'eternity', u'independent', u'I', u'who', u'upon', u'cinematic', u'director', u'core', u'icon', u'a', u'succeeded', u'i', u'Charles', u'analysis', u'person', u'so', u'2004', u'time', u'position', u'the', u'accidents', u'fact', u'songs'])\n",
      "features--\n",
      "set([u'even', u'made', u'nice', u'point', u'movie', u'loose', u'scenes', u'times', u'every', u'take', u'characters', u'time', u'nothing', u'still', u'think', u'film', u'first'])\n",
      "('common elemets %d', 10)\n",
      "com\n",
      "('adding word ', u'made')\n",
      "('adding word ', u'point')\n",
      "('adding word ', u'movie')\n",
      "('adding word ', u'scenes')\n",
      "('adding word ', u'times')\n",
      "('adding word ', u'every')\n",
      "('adding word ', u'take')\n",
      "('adding word ', u'time')\n",
      "('adding word ', u'film')\n",
      "('adding word ', u'nice')\n",
      "set d--\n",
      "set([u'What', u'abilities', u'minors', u'show', u'money', u'all', u'controversial', u'Surprise', u'still', u'yet', u'luxuries', u'(', u'had', u',', u'to', u'only', u'Michelle', u'food', u'they', u'naked', u'realistic', u'Paul', u'Elton', u'John', u'even', u'movie', u'got', u'loose', u'come', u'by', u'great', u'figured', u'of', u'1970s', u'think', u'first', u'love', u'one', u'featured', u'names', u'Gilbert', u'noticed', u'two', u'.', u'music', u'films', u'was', u'is', u'happy', u'that', u'about', u'but', u'true', u'me', u'made', u'this', u'critized', u'were', u'more', u'my', u'called', u'and', u'awesome', u'it', u'heard', u'tastes', u'film', u'!', u'no', u')', u'when', u'cinematography', u'recommended', u'becuase', u'I', u'director', u'most', u'characters', u'nothing', u'The', u'friends', u'a', u'Lewis', u'sometimes', u'It', u'so', u'the'])\n",
      "features--\n",
      "set([u'even', u'made', u'nice', u'point', u'movie', u'loose', u'scenes', u'times', u'every', u'take', u'characters', u'time', u'nothing', u'still', u'think', u'film', u'first'])\n",
      "('common elemets %d', 10)\n",
      "com\n",
      "('adding word ', u'even')\n",
      "('adding word ', u'made')\n",
      "('adding word ', u'movie')\n",
      "('adding word ', u'loose')\n",
      "('adding word ', u'characters')\n",
      "('adding word ', u'nothing')\n",
      "('adding word ', u'still')\n",
      "('adding word ', u'think')\n",
      "('adding word ', u'film')\n",
      "('adding word ', u'first')\n",
      "{u'even': 0, u'made': 1, u'point': 2, u'still': 16, u'movie': 3, u'loose': 4, u'scenes': 5, u'times': 12, u'every': 13, u'take': 6, u'characters': 14, u'time': 7, u'nothing': 15, u'nice': 11, u'think': 9, u'film': 10, u'first': 8}\n",
      " [nrows 4, ncols 17, nnz 40]\n"
     ]
    }
   ],
   "source": [
    "combinedData = np.concatenate((trainingData['review'], testData['review']))\n",
    "print(combinedData);\n",
    "docsCombineData = [word_tokenize(l) for l in combinedData]\n",
    "matCombineData  = build_matrix(docsCombineData);\n",
    "csr_info(matCombineData);\n",
    "\n",
    "# docsTestData = [word_tokenize(l) for l in testData['review']]\n",
    "# matTestData  = build_matrix(docsTestData)\n",
    "# csr_info(matTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1368,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaledData = csr_idf(matCombineData, copy=True)\n",
    "normalizedData = csr_l2normalize(scaledData, copy=True)\n",
    "# print(\"csr matrix:\", matTrainData.todense(), \"\\n\")\n",
    "# print(\"scaled csr matrix:\", scaledTrainData.todense(), \"\\n\")\n",
    "# print(\"normalized csr matrix:\", normalizedTrainData.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaledTestData = csr_idf(matTestData, copy=True)\n",
    "# normalizedTestData = csr_l2normalize(scaledTestData, copy=True)\n",
    "# print(\"csr matrix:\", matTestData.todense(), \"\\n\")\n",
    "# print(\"scaled csr matrix:\", scaledTestData.todense(), \"\\n\")\n",
    "# print(\"normalized csr matrix:\", normalizedTestData.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [nrows 4, ncols 17, nnz 40]\n",
      " [nrows 2, ncols 17, nnz 20]\n",
      "  (0, 0)\t0.364740858496\n",
      "  (0, 1)\t0.151381133795\n",
      "  (0, 2)\t0.364740858496\n",
      "  (0, 3)\t0.0\n",
      "  (0, 4)\t0.151381133795\n",
      "  (0, 5)\t0.364740858496\n",
      "  (0, 6)\t0.364740858496\n",
      "  (0, 7)\t0.151381133795\n",
      "  (0, 8)\t0.364740858496\n",
      "  (0, 9)\t0.364740858496\n",
      "  (0, 10)\t0.0\n",
      "  (0, 11)\t0.364740858496\n",
      "----\n",
      "  (0, 3)\t0.0\n",
      "  (0, 4)\t0.199120889896\n",
      "  (0, 7)\t0.199120889896\n",
      "  (0, 10)\t0.0\n",
      "  (0, 12)\t0.479766021727\n",
      "  (0, 13)\t0.479766021727\n",
      "  (0, 14)\t0.479766021727\n",
      "  (0, 15)\t0.479766021727\n",
      "----\n",
      "  (0, 1)\t0.164773822763\n",
      "  (0, 2)\t0.397009482394\n",
      "  (0, 3)\t0.0\n",
      "  (0, 5)\t0.397009482394\n",
      "  (0, 6)\t0.397009482394\n",
      "  (0, 7)\t0.164773822763\n",
      "  (0, 10)\t0.0\n",
      "  (0, 11)\t0.397009482394\n",
      "  (0, 12)\t0.397009482394\n",
      "  (0, 13)\t0.397009482394\n",
      "----\n",
      "  (0, 0)\t0.327130984845\n",
      "  (0, 1)\t0.135771625887\n",
      "  (0, 3)\t0.0\n",
      "  (0, 4)\t0.135771625887\n",
      "  (0, 8)\t0.327130984845\n",
      "  (0, 9)\t0.327130984845\n",
      "  (0, 10)\t0.0\n",
      "  (0, 14)\t0.327130984845\n",
      "  (0, 15)\t0.327130984845\n",
      "  (0, 16)\t0.654261969689\n",
      "----\n",
      "2\n",
      "2\n",
      " [nrows 2, ncols 17, nnz 20]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Calculate consine similarity between training and test normalized data\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def calculate_cosine_sim(train,test):\n",
    "    cosineSimilarity = cosine_similarity(train,test)\n",
    "    return cosineSimilarity\n",
    "csr_info(normalizedData)\n",
    "train = normalizedData[0:(len(trainingData))];\n",
    "csr_info(train)\n",
    "print(normalizedData[0:1]);\n",
    "print('----')\n",
    "print(normalizedData[1:2]);\n",
    "print('----')\n",
    "print(normalizedData[2:3]);\n",
    "print('----')\n",
    "print(normalizedData[3:4]);\n",
    "print('----')\n",
    "print(len(trainingData));\n",
    "print(len(testData));\n",
    "test = normalizedData[len(trainingData):len(trainingData)+len(testData)];\n",
    "csr_info(test)\n",
    "cosineSimilarity = calculate_cosine_sim(train, test);\n",
    "print(len(cosineSimilarity));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[0]\n",
      "('review', -1)\n",
      "1\n",
      "0\n",
      "[0 1]\n",
      "[0]\n",
      "('review', -1)\n",
      "1\n",
      "0\n",
      "('count : ', 2)\n"
     ]
    }
   ],
   "source": [
    "# Find K nearest neighbors and write to test file\n",
    "f = open('data/test_out.dat.txt', 'w')\n",
    "count = 0\n",
    "for row in cosineSimilarity:\n",
    "    k=1\n",
    "    kLargestSimilarities = np.argpartition(-row, k)\n",
    "    print(kLargestSimilarities)\n",
    "    neighbors = kLargestSimilarities[:k]\n",
    "    print(neighbors)\n",
    "    neighbourReviewClassList = []\n",
    "    neighbourReviewClassNegative = 0\n",
    "    neighbourReviewClassPositive = 0\n",
    "\n",
    "    for review in neighbors:\n",
    "        print('review' , trainingData['rating'][review])\n",
    "        if int(trainingData['rating'][review]) == -1:\n",
    "            neighbourReviewClassNegative+=1\n",
    "        elif int(trainingData['rating'][review]) == 1:\n",
    "            neighbourReviewClassPositive+=1\n",
    "    print(neighbourReviewClassNegative)\n",
    "    print(neighbourReviewClassPositive)\n",
    "    if neighbourReviewClassNegative > neighbourReviewClassPositive:\n",
    "        f.write('-1\\n')\n",
    "        count+=1\n",
    "    else:\n",
    "        f.write('+1\\n')\n",
    "        count+=1\n",
    "\n",
    "print(\"count : \",count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/test_out.dat.txt\", \"r\") as fh:\n",
    "    linesOfFormat = fh.readlines()\n",
    "print(len(linesOfFormat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
