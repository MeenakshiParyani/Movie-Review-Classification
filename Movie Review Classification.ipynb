{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy import spatial\n",
    "\n",
    "import matplotlib.pyplot as plt # side-stepping mpl backend\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import pairwise\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "# from sklearn import cross_validation\n",
    "import heapq\n",
    "import string\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "trainingData  = pd.read_csv('data/train.dat.txt', sep=\"\\t\", encoding='utf-8', header=None, names=[\"rating\",\"review\"])[0:5];\n",
    "testData = pd.read_csv('data/test.dat.txt', sep=\"\\t\", encoding='utf-8', header=None, names=[\"review\"])[0:5];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Cleaning\n",
      "   rating                                             review\n",
      "0      -1  Although a film with Bruce Willis is always wo...\n",
      "After Cleaning\n",
      "[[u'although', u'film', u'bruce', u'willis', u'always', u'worth', u'watching', u'better', u'skip', u'watched', u'television', u'plunk', u'cash', u'lucky', u'plot', u'develops', u'slowly', u'slowly', u'although', u'first', u'minutes', u'quite', u'believable', u'gets', u'unbelievable', u'towards', u'highly', u'questionable', u'seasoned', u'soldier', u'like', u'waters', u'would', u'disobey', u'direct', u'orders', u'even', u'would', u'rest', u'platoon', u'would', u'know', u'puts', u'direct', u'danger', u'know', u'certainly', u'follow', u'heck', u'says', u'despite', u'direct', u'orders', u'remember', u'still', u'nice', u'scenes', u'movie', u'somewhat', u'save', u'village', u'total', u'population', u'massacred', u'rebels', u'well', u'save', u'dozen', u'villagers', u'rest', u'already', u'killed', u'strange', u'part', u'take', u'trucks', u'rebels', u'left', u'behind', u'rather', u'foot', u'maybe', u'roads', u'unsafe', u'explanation', u'anyway', u'think', u'earned', u'movie', u'point', u'gave', u'made', u'movie', u'insult', u'brain', u'hence', u'completely', u'unbelievable', u'group', u'soldiers', u'kill', u'many', u'rebels', u'without', u'hurt', u'killed', u'near', u'loose', u'comrades', u'fight', u'army', u'nearly', u'believe', u'fight', u'army', u'many', u'kill', u'hundreds', u'loose', u'rounds', u'round', u'ammo', u'never', u'grenades', u'claymore', u'mines', u'machine', u'even', u'stuff', u'carrying', u'around', u'even', u'laptop', u'shows', u'activity', u'enemy', u'rebels', u'laptop', u'battery', u'goes', u'days', u'really', u'think', u'crap.', u'guess', u'turn', u'brain', u'completely', u'accept', u'rebels', u'bunch', u'idiots', u'give', u'movie', u'high', u'rating', u'skip', u'saves', u'time'], [u'movie', u'slower', u'molasses', u'january', u'alaska', u'togeather', u'preview', u'award', u'managing', u'every', u'seconds', u'interisting', u'preview', u'wake', u'people', u'watching', u'several', u'times', u'felt', u'woken', u'film', u'taken', u'hoping', u'something', u'actually', u'happen', u'nothing', u'ever', u'easy', u'loose', u'track', u'people', u'motives', u'characters', u'flat', u'uninteristing', u'movie', u'hoped', u'everyone', u'would', u'died', u'everyone', u'runs', u'around', u'either', u'contemptible', u'petty', u'pitiful', u'usually', u'three', u'worse', u'watched', u'minute', u'added', u'features', u'kicks', u'giggles', u'understand', u'people', u'smug', u'socially', u'aware', u'spend', u'time', u'movie', u'patting', u'back', u'might', u'worth', u'watching', u'brought', u'expecting', u'excitement', u'lecture', u'social', u'awareness', u'blery', u'eyes', u'sandman'], [u'interesting', u'film', u'actual', u'event', u'took', u'place', u'civil', u'vermont', u'kept', u'attention', u'regret', u'viewing', u'ever', u'read', u'raid', u'incident', u'curious', u'rebels', u'pulled', u'enjoy', u'historical', u'films', u'era.', u'major', u'complaint', u'confederate', u'uniforms', u'look', u'good', u'acting', u'little', u'stiff', u'times', u'like', u'eating', u'mashed', u'potatoes', u'teeth', u'wounded', u'soldier', u'playing', u'fetch', u'hound', u'little', u'strange', u'overall', u'descent', u'film'], [u'painfully', u'obvious', u'people', u'made', u'movie', u'never', u'seen', u'brilliant', u'spoofs', u'naked', u'shots', u'movie', u'terrible', u'actors', u'would', u'know', u'acting', u'even', u'face', u'felt', u'like', u'watching', u'total', u'pile', u'rubbish.', u'movie', u'stupid', u'humor', u'ever', u'sure', u'could', u'make', u'better', u'movie', u'friends', u'amazing', u'movie', u'fail', u'much', u'single', u'clever', u'funny', u'line', u'trace', u'intelligence', u'behind', u'pathetic', u'movie', u'like', u'meet', u'person', u'actually', u'likes', u'movie', u'yuck'], [u'movie', u'really', u'mixed', u'hand', u'story', u'concept', u'movie', u'really', u'good', u'tense', u'nice', u'plot', u'twists', u'hand', u'told', u'slow', u'without', u'style', u'uninvolved', u'still', u'regard', u'cause', u'average', u'thriller', u'simply', u'fine', u'cast.', u'maybe', u'sean', u'connery', u'miscast', u'role', u'mean', u'really', u'believable', u'main', u\"'hero\", u'father', u'young', u'daughter', u'played', u'still', u'young', u'scarlett', u'johansson', u'husband', u'kate', u'capshaw', u'feel', u'simply', u'role', u'really', u'credible', u'however', u'sean', u'connerey', u'course', u'great', u'actor', u'reason', u'still', u'able', u'carry', u'movie', u'good', u'course', u'helped', u'solid', u'supporting', u'cast', u'consists', u'actors', u'like', u'laurence', u'fishburne', u'blair', u'underwood', u'beatty', u'hope', u'lange', u'lynne', u'thigpen', u'harris', u'actors', u'really', u'good', u'highly', u'underused', u'time', u'real', u'shame', u'well', u'missed', u'opportunity', u'especially', u'harris', u'totally', u'great', u'role', u'psychopathic', u'serial', u'killer', u'truly', u'chilling', u'acting', u'superbly', u'normally', u'play', u'ruthless', u'chilling', u'sort', u'roles', u'movies', u'really', u'surprises', u'role', u'performance', u'alone', u'already', u'enough', u'reason', u'watch', u'movie', u'however', u'fact', u'story', u'told', u'without', u'much', u'style', u'formulaic', u'none', u'characters', u'movie', u'really', u'work', u'well', u'feels', u'distant.', u'really', u'storytelling', u'kills', u'movie', u'fine', u'potential', u'arne', u'glimcher', u'directs', u'movie', u'little', u'style', u'keeps', u'pace', u'times', u'viewers', u'never', u'really', u'involved', u'story', u'characters.', u'really', u'cause', u'enough', u'potential', u'fine', u'cast', u'slick', u'story', u'unexpected', u'twists', u'turns', u'nothing', u'seems', u'cast', u'story', u'reason', u'movie', u'still', u'average', u'thriller', u'probably', u'still', u'please', u'genre', u'however', u'eternal', u'shame', u'movie', u'lacking', u'story', u'telling', u'style', u'else', u'movie', u'could', u'real', u'classic', u'genre.', u'7/10']]\n",
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "print('Before Cleaning');\n",
    "print (trainingData[0:1])\n",
    "\n",
    "def preProcess(reviews):\n",
    "#     print(reviews);\n",
    "    processedReviews = [];\n",
    "    for review in reviews:\n",
    "        tokens = word_tokenize(review);\n",
    "        filteredTokens = [];\n",
    "        for token in list(tokens):\n",
    "#             print(token);\n",
    "            # if it is a stopword then eliminate\n",
    "            if token.lower() in stopwords.words('english'):\n",
    "#                 print('removing stopword ' + token);\n",
    "                continue;\n",
    "            # if it is punctuation then eliminate\n",
    "            if token.lower() in set(string.punctuation):\n",
    "#                 print('removing punct ' + token);\n",
    "                continue;\n",
    "            if len(token)<=3:\n",
    "#                 print('removing small ' + token);\n",
    "                continue;\n",
    "            token = token.lower();\n",
    "            filteredTokens.append(token);\n",
    "#         print(filteredTokens);\n",
    "        processedReviews.append(filteredTokens);\n",
    "#     print(len(processedReviews));\n",
    "    return processedReviews;\n",
    "print('After Cleaning')\n",
    "XTrain = preProcess(trainingData['review']);\n",
    "print(XTrain);\n",
    "print (len(XTrain));\n",
    "XTest = preProcess(testData['review']);\n",
    "print (len(XTest));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 375.\n",
      "Number of unique words: 277.\n",
      "375\n",
      "277\n"
     ]
    }
   ],
   "source": [
    "# count frequencies for all words in the Training data\n",
    "def countFrequency(data):\n",
    "    wordCountInData = Counter()\n",
    "    for d in data:\n",
    "    #     print(d);\n",
    "        for w in d:\n",
    "    #         print(w);\n",
    "            if w not in wordCountInData:\n",
    "                wordCountInData[w]=1\n",
    "            else:\n",
    "                wordCountInData[w] += 1\n",
    "    print(\"Number of unique words: %d.\" % len(wordCountInData));\n",
    "    return wordCountInData;\n",
    "\n",
    "wordCountInTrainingData = countFrequency(XTrain);\n",
    "wordCountInTestData = countFrequency(XTest);\n",
    "print(len(wordCountInTrainingData));\n",
    "print(len(wordCountInTestData));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188\n",
      "139\n"
     ]
    }
   ],
   "source": [
    "#Top percent of training data\n",
    "topPct = 0.5;\n",
    "topPctOfTraining = wordCountInTrainingData.most_common(int(round(len(wordCountInTrainingData)*topPct)));\n",
    "topPctOfTest = wordCountInTestData.most_common(int(round(len(wordCountInTestData)*topPct)));\n",
    "\n",
    "# Get a set of topPctOfTraining\n",
    "topPctOfTrainingSet = set()\n",
    "for word in topPctOfTraining:\n",
    "    topPctOfTrainingSet.add(word[0]);\n",
    "\n",
    "# Get a set of topPctOfTest\n",
    "topPctOfTestSet = set()\n",
    "for word in topPctOfTest:\n",
    "    topPctOfTestSet.add(word[0]);\n",
    "    \n",
    "# print(topPctOfTrainingSet);\n",
    "# print(topPctOfTestSet);\n",
    "print(len(topPctOfTrainingSet));\n",
    "print(len(topPctOfTestSet));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words common in both test and train: 21.\n"
     ]
    }
   ],
   "source": [
    "testTrainSet =  set.intersection(topPctOfTrainingSet,topPctOfTestSet);\n",
    "print(\"Number of unique words common in both test and train: %d.\" % len(testTrainSet));\n",
    "# print(testTrainSet);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "cnt = Counter(testTrainSet);\n",
    "top_percentile = 1.0\n",
    "features = cnt.most_common(int(round(len(cnt)*top_percentile)))\n",
    "featuresCount = len(features)\n",
    "# print(features);\n",
    "print(featuresCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "[u'enjoy', u'even', u'great', u'made', u'like', u'supporting', u'brilliant', u'movie', u'never', u'watch', u'actors', u'worth', u'role', u'know', u'still', u'time', u'well', u'every', u'work', u'think', u'film']\n"
     ]
    }
   ],
   "source": [
    "featureList= [];\n",
    "for feature in features:\n",
    "    featureList.append(feature[0])\n",
    "print(len(featureList));\n",
    "print(featureList);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Buid CSR matrix\n",
    "\n",
    "from collections import Counter\n",
    "from scipy.sparse import csr_matrix\n",
    "def build_matrix(docs):\n",
    "    r\"\"\" Build sparse matrix from a list of documents, \n",
    "    each of which is a list of word/terms in the document.  \n",
    "    \"\"\"\n",
    "    dim = len(featureList)\n",
    "    feature_set = set(featureList[:dim])\n",
    "    nrows = len(docs)\n",
    "    idx = {}\n",
    "    tid = 0\n",
    "    nnz = 0\n",
    "    for d in docs:\n",
    "        set_d = set(d)\n",
    "        d = list(set.intersection(feature_set,set_d))\n",
    "        nnz += len(set(d))\n",
    "        for w in d:\n",
    "            if w not in idx:\n",
    "                idx[w] = tid\n",
    "                tid += 1\n",
    "    ncols = len(idx)\n",
    "        \n",
    "    # set up memory\n",
    "    ind = np.zeros(nnz, dtype=np.int)\n",
    "    val = np.zeros(nnz, dtype=np.double)\n",
    "    ptr = np.zeros(nrows+1, dtype=np.int)\n",
    "    i = 0  # document ID / row counter\n",
    "    n = 0  # non-zero counter\n",
    "    # transfer values\n",
    "    for d in docs:\n",
    "        set_d = set(d)\n",
    "        d = list(set.intersection(feature_set,set_d))\n",
    "        cnt = Counter(d)\n",
    "        keys = list(k for k,_ in cnt.most_common())\n",
    "        l = len(keys)\n",
    "        for j,k in enumerate(keys):\n",
    "            ind[j+n] = idx[k]\n",
    "            val[j+n] = cnt[k]\n",
    "        ptr[i+1] = ptr[i] + l\n",
    "        n += l\n",
    "        i += 1\n",
    "            \n",
    "    mat = csr_matrix((val, ind, ptr), shape=(nrows, ncols), dtype=np.double)\n",
    "    mat.sort_indices()\n",
    "    \n",
    "    return mat\n",
    "\n",
    "\n",
    "def csr_info(mat, name=\"\", non_empy=False):\n",
    "    r\"\"\" Print out info about this CSR matrix. If non_empy, \n",
    "    report number of non-empty rows and cols as well\n",
    "    \"\"\"\n",
    "    if non_empy:\n",
    "        print(\"%s [nrows %d (%d non-empty), ncols %d (%d non-empty), nnz %d]\" % (\n",
    "                name, mat.shape[0], \n",
    "                sum(1 if mat.indptr[i+1] > mat.indptr[i] else 0 \n",
    "                for i in range(mat.shape[0])), \n",
    "                mat.shape[1], len(np.unique(mat.indices)), \n",
    "                len(mat.data)))\n",
    "    else:\n",
    "        print( \"%s [nrows %d, ncols %d, nnz %d]\" % (name, \n",
    "                mat.shape[0], mat.shape[1], len(mat.data)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [nrows 5, ncols 21, nnz 34]\n",
      "  (0, 0)\t1.0\n",
      "  (0, 1)\t1.0\n",
      "  (0, 2)\t1.0\n",
      "  (0, 3)\t1.0\n",
      "  (0, 4)\t1.0\n",
      "  (0, 5)\t1.0\n",
      "  (0, 6)\t1.0\n",
      "  (0, 7)\t1.0\n"
     ]
    }
   ],
   "source": [
    "docsTrainData = [l.split() for l in trainingData['review']]\n",
    "matTrainData  = build_matrix(docsTrainData);\n",
    "csr_info(matTrainData);\n",
    "\n",
    "print (matTrainData[:1])\n",
    "\n",
    "print(testData[:1])\n",
    "docsTestData = [l.split() for l in testData['review']]\n",
    "matTestData  = build_matrix(docsTestData)\n",
    "csr_info(matTestData)\n",
    "print (matTestData[:1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
