{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy import spatial\n",
    "\n",
    "import matplotlib.pyplot as plt # side-stepping mpl backend\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import pairwise\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "# from sklearn import cross_validation\n",
    "import heapq\n",
    "import string\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "trainingData  = pd.read_csv('data/train.dat.txt', sep=\"\\t\", encoding='utf-8', header=None, names=[\"rating\",\"review\"]);\n",
    "testData = pd.read_csv('data/test.dat.txt', sep=\"\\t\", encoding='utf-8', header=None, names=[\"review\"]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Cleaning\n",
      "   rating                                             review\n",
      "0      -1  Although a film with Bruce Willis is always wo...\n",
      "After Cleaning\n",
      "[[u'although', u'film', u'bruce', u'willis', u'always', u'worth', u'watching', u'better', u'skip', u'watched', u'television', u'plunk', u'cash', u'lucky', u'plot', u'develops', u'slowly', u'slowly', u'although', u'first', u'minutes', u'quite', u'believable', u'gets', u'unbelievable', u'towards', u'highly', u'questionable', u'seasoned', u'soldier', u'like', u'waters', u'would', u'disobey', u'direct', u'orders', u'even', u'would', u'rest', u'platoon', u'would', u'know', u'puts', u'direct', u'danger', u'know', u'certainly', u'follow', u'heck', u'says', u'despite', u'direct', u'orders', u'remember', u'still', u'nice', u'scenes', u'movie', u'somewhat', u'save', u'village', u'total', u'population', u'massacred', u'rebels', u'well', u'save', u'dozen', u'villagers', u'rest', u'already', u'killed', u'strange', u'part', u'take', u'trucks', u'rebels', u'left', u'behind', u'rather', u'foot', u'maybe', u'roads', u'unsafe', u'explanation', u'anyway', u'think', u'earned', u'movie', u'point', u'gave', u'made', u'movie', u'insult', u'brain', u'hence', u'completely', u'unbelievable', u'group', u'soldiers', u'kill', u'many', u'rebels', u'without', u'hurt', u'killed', u'near', u'loose', u'comrades', u'fight', u'army', u'nearly', u'believe', u'fight', u'army', u'many', u'kill', u'hundreds', u'loose', u'rounds', u'round', u'ammo', u'never', u'grenades', u'claymore', u'mines', u'machine', u'even', u'stuff', u'carrying', u'around', u'even', u'laptop', u'shows', u'activity', u'enemy', u'rebels', u'laptop', u'battery', u'goes', u'days', u'really', u'think', u'crap.', u'guess', u'turn', u'brain', u'completely', u'accept', u'rebels', u'bunch', u'idiots', u'give', u'movie', u'high', u'rating', u'skip', u'saves', u'time']]\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "print('Before Cleaning');\n",
    "print (trainingData[0:1])\n",
    "\n",
    "def preProcess(reviews):\n",
    "#     print(reviews);\n",
    "    processedReviews = [];\n",
    "    for review in reviews:\n",
    "        tokens = word_tokenize(review);\n",
    "        filteredTokens = [];\n",
    "        for token in list(tokens):\n",
    "#             print(token);\n",
    "            # if it is a stopword then eliminate\n",
    "            if token.lower() in stopwords.words('english'):\n",
    "#                 print('removing stopword ' + token);\n",
    "                continue;\n",
    "            # if it is punctuation then eliminate\n",
    "            if token.lower() in set(string.punctuation):\n",
    "#                 print('removing punct ' + token);\n",
    "                continue;\n",
    "            if len(token)<=3:\n",
    "#                 print('removing small ' + token);\n",
    "                continue;\n",
    "            token = token.lower();\n",
    "            filteredTokens.append(token);\n",
    "#         print(filteredTokens);\n",
    "        processedReviews.append(filteredTokens);\n",
    "#     print(len(processedReviews));\n",
    "    return processedReviews;\n",
    "print('After Cleaning')\n",
    "XTrain = preProcess(trainingData['review'][0:100]);\n",
    "print(XTrain[0:1]);\n",
    "print (len(XTrain));\n",
    "XTest = preProcess(testData['review'][0:100]);\n",
    "print (len(XTest));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 4413.\n",
      "Number of unique words: 4175.\n",
      "4413\n",
      "4175\n"
     ]
    }
   ],
   "source": [
    "# count frequencies for all words in the Training data\n",
    "def countFrequency(data):\n",
    "    wordCountInData = Counter()\n",
    "    for d in data:\n",
    "    #     print(d);\n",
    "        for w in d:\n",
    "    #         print(w);\n",
    "            if w not in wordCountInData:\n",
    "                wordCountInData[w]=1\n",
    "            else:\n",
    "                wordCountInData[w] += 1\n",
    "    print(\"Number of unique words: %d.\" % len(wordCountInData));\n",
    "    return wordCountInData;\n",
    "\n",
    "wordCountInTrainingData = countFrequency(XTrain);\n",
    "wordCountInTestData = countFrequency(XTest);\n",
    "print(len(wordCountInTrainingData));\n",
    "print(len(wordCountInTestData));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "662\n",
      "626\n"
     ]
    }
   ],
   "source": [
    "#Top percent of training data\n",
    "top15Pct = 0.15;\n",
    "top15PctOfTraining = wordCountInTrainingData.most_common(int(round(len(wordCountInTrainingData)*top15Pct)))\n",
    "top15PctOfTest = wordCountInTestData.most_common(int(round(len(wordCountInTestData)*top15Pct)));\n",
    "print(len(top15PctOfTraining));\n",
    "print(len(top15PctOfTest));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
